{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from PyDictionary import PyDictionary\n",
    "dictionary=PyDictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab():\n",
    "    with open('../Sample Data/Keywords.txt') as f:\n",
    "        l=(f.readlines())\n",
    "    vocab = []\n",
    "    for it in l:\n",
    "        if(len(it)>2):\n",
    "            vocab.append(it.strip()[1:-2])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotwords(text):\n",
    "    \n",
    "    result = []\n",
    "    for it in text:\n",
    "        if it in vocab:\n",
    "            result.append(it)\n",
    "    pos_tag = ['PROPN', 'NOUN'] # extract proper nouns and nouns\n",
    "    doc = nlp(text.lower()) # 2\n",
    "  \n",
    "    for token in doc:\n",
    "        \n",
    "        # skip if puntuation or stop word\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        # 4\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "        \n",
    "                \n",
    "    return list(set(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ='''\n",
    "Normalization is a process to eliminate the flaws of a database with bad design. A poorly designed database is inconsistent and create issues while adding, deleting or updating information.\n",
    "\n",
    "The following makes Database Normalization a crucial step in database design process −\n",
    "\n",
    "Resolving the database anomalies\n",
    "The forms of Normalization i.e. 1NF, 2NF, 3NF, BCF, 4NF and 5NF remove all the Insert, Update and Delete anomalies.\n",
    "\n",
    "Insertion Anomaly occurs when you try to insert data in a record that does not exist.\n",
    "\n",
    "Deletion Anomaly is when a data is to be deleted and due to the poor deign of database, other record also deletes.\n",
    "\n",
    "Eliminate Redundancy of Data\n",
    "Storing same data item multiple times is known as Data Redundancy. A normalized table do not have the issue of redundancy of data.\n",
    "\n",
    "Data Dependency\n",
    "The data gets stored in the correct table and ensures normalization.\n",
    "\n",
    "Isolation of Data\n",
    "A good designed database states that the changes in one table or field do not affect other. This is achieved through Normalization.\n",
    "\n",
    "Data Consistency\n",
    "While updating if a record is left, it can led to inconsistent data, Normalization resolves it and ensures Data Consistency.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities():\n",
    "    entities={}\n",
    "    doc = nlp(data)\n",
    "    for entity in doc.ents:\n",
    "        if(entity.label_ not in entities.keys()):\n",
    "            entities[entity.label_] = []\n",
    "            entities[entity.label_].append(entity)\n",
    "        else:\n",
    "            entities[entity.label_].append(entity)\n",
    "    return(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_data(data):\n",
    "    for it in data.split():\n",
    "        if(it.lower() in keywords):\n",
    "            bolded_string = \"\\033[1m\" + it + \"\\033[0m\"\n",
    "            print(bolded_string,end= ' ')\n",
    "        else:\n",
    "            print(it,end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = get_vocab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalization is a process to eliminate the flaws of a database with bad design. A poorly designed database is inconsistent and create issues while adding, deleting or updating information.\n",
      "\n",
      "The following makes Database Normalization a crucial step in database design process −\n",
      "\n",
      "Resolving the database anomalies\n",
      "The forms of Normalization i.e. 1NF, 2NF, 3NF, BCF, 4NF and 5NF remove all the Insert, Update and Delete anomalies.\n",
      "\n",
      "Insertion Anomaly occurs when you try to insert data in a record that does not exist.\n",
      "\n",
      "Deletion Anomaly is when a data is to be deleted and due to the poor deign of database, other record also deletes.\n",
      "\n",
      "Eliminate Redundancy of Data\n",
      "Storing same data item multiple times is known as Data Redundancy. A normalized table do not have the issue of redundancy of data.\n",
      "\n",
      "Data Dependency\n",
      "The data gets stored in the correct table and ensures normalization.\n",
      "\n",
      "Isolation of Data\n",
      "A good designed database states that the changes in one table or field do not affect other. This is achieved through Normalization.\n",
      "\n",
      "Data Consistency\n",
      "While updating if a record is left, it can led to inconsistent data, Normalization resolves it and ensures Data Consistency.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3nf',\n",
       " 'following',\n",
       " 'step',\n",
       " 'data',\n",
       " 'information',\n",
       " '5nf',\n",
       " 'flaws',\n",
       " 'issue',\n",
       " 'anomalies',\n",
       " 'dependency',\n",
       " 'redundancy',\n",
       " 'design',\n",
       " 'normalization',\n",
       " 'changes',\n",
       " 'process',\n",
       " 'isolation',\n",
       " 'forms',\n",
       " 'issues',\n",
       " 'field',\n",
       " '2nf',\n",
       " 'database',\n",
       " 'anomaly',\n",
       " 'insert',\n",
       " 'item',\n",
       " 'deletion',\n",
       " 'times',\n",
       " 'deign',\n",
       " 'table',\n",
       " 'consistency',\n",
       " 'insertion',\n",
       " 'record']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = get_hotwords(data)\n",
    "keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNormalization\u001b[0m is a \u001b[1mprocess\u001b[0m to eliminate the \u001b[1mflaws\u001b[0m of a \u001b[1mdatabase\u001b[0m with bad design. A poorly designed \u001b[1mdatabase\u001b[0m is inconsistent and create \u001b[1missues\u001b[0m while adding, deleting or updating information. The \u001b[1mfollowing\u001b[0m makes \u001b[1mDatabase\u001b[0m \u001b[1mNormalization\u001b[0m a crucial \u001b[1mstep\u001b[0m in \u001b[1mdatabase\u001b[0m \u001b[1mdesign\u001b[0m \u001b[1mprocess\u001b[0m − Resolving the \u001b[1mdatabase\u001b[0m \u001b[1manomalies\u001b[0m The \u001b[1mforms\u001b[0m of \u001b[1mNormalization\u001b[0m i.e. 1NF, 2NF, 3NF, BCF, 4NF and \u001b[1m5NF\u001b[0m remove all the Insert, Update and Delete anomalies. \u001b[1mInsertion\u001b[0m \u001b[1mAnomaly\u001b[0m occurs when you try to \u001b[1minsert\u001b[0m \u001b[1mdata\u001b[0m in a \u001b[1mrecord\u001b[0m that does not exist. \u001b[1mDeletion\u001b[0m \u001b[1mAnomaly\u001b[0m is when a \u001b[1mdata\u001b[0m is to be deleted and due to the poor \u001b[1mdeign\u001b[0m of database, other \u001b[1mrecord\u001b[0m also deletes. Eliminate \u001b[1mRedundancy\u001b[0m of \u001b[1mData\u001b[0m Storing same \u001b[1mdata\u001b[0m \u001b[1mitem\u001b[0m multiple \u001b[1mtimes\u001b[0m is known as \u001b[1mData\u001b[0m Redundancy. A normalized \u001b[1mtable\u001b[0m do not have the \u001b[1missue\u001b[0m of \u001b[1mredundancy\u001b[0m of data. \u001b[1mData\u001b[0m \u001b[1mDependency\u001b[0m The \u001b[1mdata\u001b[0m gets stored in the correct \u001b[1mtable\u001b[0m and ensures normalization. \u001b[1mIsolation\u001b[0m of \u001b[1mData\u001b[0m A good designed \u001b[1mdatabase\u001b[0m states that the \u001b[1mchanges\u001b[0m in one \u001b[1mtable\u001b[0m or \u001b[1mfield\u001b[0m do not affect other. This is achieved through Normalization. \u001b[1mData\u001b[0m \u001b[1mConsistency\u001b[0m While updating if a \u001b[1mrecord\u001b[0m is left, it can led to inconsistent data, \u001b[1mNormalization\u001b[0m resolves it and ensures \u001b[1mData\u001b[0m Consistency. "
     ]
    }
   ],
   "source": [
    "highlight_data(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
